{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/argan719/DataScience/blob/main/val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXG_HJhqDLlS"
      },
      "source": [
        "# Open Data Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhmcugEODLlU",
        "outputId": "0ce78b27-a28f-4f91-da3f-a55e129d1e8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.107 ðŸš€ Python-3.10.10 torch-2.0.0 CUDA:5 (NVIDIA GeForce RTX 3070, 7982MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Disk3/snu_project/opendata/CVC-ClinicDB/yolo-format.cache... 612 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 612/612 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:07<00:00,  2.07it/s]\n",
            "                   all        612        612      0.657      0.593      0.601      0.182\n",
            "Speed: 1.0ms preprocess, 3.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Saving runs/detect/CVC-ClinicDB-yolov8n11/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/CVC-ClinicDB-yolov8n11\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[337.411, 250.791, 299.154, 261.771]\n",
            "Polyps: 612, Max positive: 581\n",
            "0.8006535947712419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.107 ðŸš€ Python-3.10.10 torch-2.0.0 CUDA:5 (NVIDIA GeForce RTX 3070, 7982MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Disk3/snu_project/opendata/CVC-ColonDB/yolo-format.cache... 300 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:06<00:00,  1.29it/s]\n",
            "                   all        300        300      0.705      0.653      0.652      0.175\n",
            "Speed: 2.2ms preprocess, 4.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Saving runs/detect/CVC-ColonDB-yolov8n11/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/CVC-ColonDB-yolov8n11\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[533.409, 448.205, 439.408, 500.0]\n",
            "Polyps: 300, Max positive: 299\n",
            "0.9466666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.107 ðŸš€ Python-3.10.10 torch-2.0.0 CUDA:5 (NVIDIA GeForce RTX 3070, 7982MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Disk3/snu_project/opendata/ETIS-LaribPolypDB/yolo-format.cache... 196 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  1.57s/it]\n",
            "                   all        196        196      0.507       0.49      0.439      0.124\n",
            "Speed: 3.7ms preprocess, 5.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Saving runs/detect/ETIS-LaribPolypDB-yolov8n11/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/ETIS-LaribPolypDB-yolov8n11\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1156.923, 911.163, 864.397, 780.67]\n",
            "Polyps: 196, Max positive: 189\n",
            "0.7908163265306123\n"
          ]
        }
      ],
      "source": [
        "import os, json, numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_NAME = \"yolov8n11\"\n",
        "OPEN_DATASETS = (\"CVC-ClinicDB\", \"CVC-ColonDB\", \"ETIS-LaribPolypDB\")\n",
        "\n",
        "model = YOLO(f\"yolov8/runs/train/{MODEL_NAME}/weights/last.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "for ds in OPEN_DATASETS:\n",
        "    model.val(\n",
        "        data=f\"/mnt/Disk3/snu_project/opendata/{ds}/yolo-data.yaml\",\n",
        "        name=f\"{ds}-{MODEL_NAME}\",\n",
        "        device=5,\n",
        "        exist_ok=True,\n",
        "        batch=40,\n",
        "        save_json=True,\n",
        "    )\n",
        "\n",
        "    with open(f'runs/detect/{ds}-{MODEL_NAME}/predictions.json') as f:\n",
        "        pred = json.load(f)\n",
        "\n",
        "    bboxes = {}\n",
        "    for d in pred:\n",
        "        image_id = str(d['image_id'])\n",
        "        x, y, w, h = d['bbox']\n",
        "        score = d['score']\n",
        "        if score <= 0:\n",
        "            continue\n",
        "        if image_id not in bboxes:\n",
        "            bboxes[image_id] = []\n",
        "        bboxes[image_id].append(((x, y, x + w, y + h), score))\n",
        "\n",
        "    def calculate_iou(bbox1, bbox2):\n",
        "        x11, y11, x12, y12 = bbox1\n",
        "        x21, y21, x22, y22 = bbox2\n",
        "        inter = max(min(x12, x22) - max(x11, x21), 0) * max(min(y12, y22) - max(y11, y21), 0)\n",
        "        union = (x12 - x11) * (y12 - y11) + (x22 - x21) * (y22 - y21) - inter\n",
        "        return inter / max(union, 1e-12)\n",
        "\n",
        "    polyps = {}\n",
        "\n",
        "    for image in os.listdir(f'/mnt/Disk3/snu_project/opendata/{ds}/yolo-format'):\n",
        "        if image[-4:] not in ('.png', '.bmp'): continue\n",
        "        with Image.open(f'/mnt/Disk3/snu_project/opendata/{ds}/yolo-format/{image}') as im:\n",
        "            width, height = im.size\n",
        "        with open(f'/mnt/Disk3/snu_project/opendata/{ds}/yolo-format/{image[:-4]}.txt') as f:\n",
        "            for line in f.readlines():\n",
        "                try:\n",
        "                    _, x, y, w, h = map(float, line.split())\n",
        "                    true = ((x - w / 2) * width, (y - h / 2) * height, (x + w / 2) * width, (y + h / 2) * height)\n",
        "                    k = len(polyps)\n",
        "                    polyps[k] = []\n",
        "                    for bbox, score in bboxes.get(image[:-4], []):\n",
        "                        iou = calculate_iou(bbox, true)\n",
        "                        # print(image, true, bbox, iou)\n",
        "                        if iou > 0:\n",
        "                            polyps[k].append((iou, score))\n",
        "                except Exception as e:\n",
        "                    print(image, e, line)\n",
        "\n",
        "    for k, v in polyps.items():\n",
        "        v.sort()\n",
        "        vv = []\n",
        "        for x, y in v:\n",
        "            while vv and vv[-1][1] <= y:\n",
        "                vv.pop()\n",
        "            vv.append((x, y))\n",
        "        polyps[k] = vv\n",
        "\n",
        "    print(f'Polyps: {len(polyps)}, Max positive: {sum(len(v) > 0 for v in polyps.values())}')\n",
        "    print(sum(any(iou > 0.25 and score > 0.2 for iou, score in v) for v in polyps.values()) / len(polyps))\n",
        "\n",
        "    xs, ys = np.meshgrid(\n",
        "        np.linspace(1, 0, 101, False),\n",
        "        np.linspace(1, 0, 101, False),\n",
        "    )\n",
        "    zs = np.ndarray(xs.shape)\n",
        "    for i in range(zs.shape[0]):\n",
        "        for j in range(zs.shape[1]):\n",
        "            iou_thres = xs[i][j]\n",
        "            conf_thres = ys[i][j]\n",
        "            cnt = 0\n",
        "            for v in polyps.values():\n",
        "                cnt += any(iou > iou_thres and score > conf_thres for iou, score in v)\n",
        "            zs[i][j] = cnt / len(polyps)\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.set_title(f'Open Data ({ds})')\n",
        "    ax.set_xlabel('IoU threshold')\n",
        "    ax.set_ylabel('Confidence threshold')\n",
        "    ax.set_zlabel('Sensitivity')\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(1, 0)\n",
        "    ax.set_zlim(0, 1)\n",
        "    ax.plot_surface(xs, ys, zs, cmap='plasma', rstride=1, cstride=1, antialiased=False, linewidth=0)\n",
        "    ax.plot_wireframe(xs, ys, zs, cstride=5, rstride=5, color='black')\n",
        "    # ax.scatter(xs, ys, zs, c=zs, cmap='viridis', marker='.', alpha=0.5)\n",
        "    fig.show()\n",
        "    fig.savefig(f'sensitivity_{ds}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwVrqfKnDLlX"
      },
      "source": [
        "### Test Data Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6AOp26GDLlX",
        "outputId": "68d7f4a8-d2b5-412c-8396-669849c0e626"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.107 ðŸš€ Python-3.10.10 torch-2.0.0 CUDA:5 (NVIDIA GeForce RTX 3070, 7982MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/Disk3/snu_project/jeehak/testset-640x640/labels.cache... 20050 images, 6051 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20050/20050 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 502/502 [02:53<00:00,  2.89it/s] \n",
            "                   all      20050      14236      0.577      0.457      0.418      0.129\n",
            "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Saving runs/detect/val/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.yolo.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7fc6724c11e0>\n",
              "fitness: 0.15775537004406678\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.12884])\n",
              "names: {0: 'polyp'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.5773938135468589, 'metrics/recall(B)': 0.45701039617870187, 'metrics/mAP50(B)': 0.4179685072821725, 'metrics/mAP50-95(B)': 0.1288427992398328, 'fitness': 0.15775537004406678}\n",
              "save_dir: PosixPath('runs/detect/val')\n",
              "speed: {'preprocess': 0.18504429339173428, 'inference': 1.5862106028340404, 'loss': 0.000549254572005046, 'postprocess': 1.0529442856139375}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "MODEL_NAME = \"yolov8n12\"\n",
        "model = YOLO(f\"yolov8/runs/train/{MODEL_NAME}/weights/last.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "model.val(\n",
        "    data=\"testset-640x640/data.yaml\",\n",
        "    device=5,\n",
        "    exist_ok=True,\n",
        "    batch=40,\n",
        "    save_json=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIlEZCnTDLlX",
        "outputId": "86e8ea83-29fb-4c49-fc0b-2ee1e65321eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polyps: 45, Max positive: 45\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "import os, json, cv2, numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "with open('runs/detect/val/predictions.json') as f:\n",
        "    pred = json.load(f)\n",
        "\n",
        "bboxes = {}\n",
        "for d in pred:\n",
        "    image_id = d['image_id']\n",
        "    x, y, w, h = d['bbox']\n",
        "    score = d['score']\n",
        "    if score <= 0:\n",
        "        continue\n",
        "    if image_id not in bboxes:\n",
        "        bboxes[image_id] = []\n",
        "    bboxes[image_id].append(((x, y, x + w, y + h), score))\n",
        "\n",
        "def calculate_iou(bbox1, bbox2):\n",
        "    x11, y11, x12, y12 = bbox1\n",
        "    x21, y21, x22, y22 = bbox2\n",
        "    inter = max(min(x12, x22) - max(x11, x21), 0) * max(min(y12, y22) - max(y11, y21), 0)\n",
        "    union = (x12 - x11) * (y12 - y11) + (x22 - x21) * (y22 - y21) - inter\n",
        "    return inter / max(union, 1e-12)\n",
        "\n",
        "polyps = {}\n",
        "sizes = {}\n",
        "\n",
        "for image in os.listdir('testset-640x640/images'):\n",
        "    video = image.rsplit('-', 1)[0]\n",
        "    if video not in sizes:\n",
        "        vid = cv2.VideoCapture(f'/mnt/Disk3/snu_project/testdata/videos/{video.replace(\"-\", \"/\")}.mp4')\n",
        "        height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "        width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "        scale = 640 / max(height, width)\n",
        "        sizes[video] = scale\n",
        "    scale = sizes[video]\n",
        "    label = f'/mnt/Disk3/snu_project/testdata/videos/{image[:-4].replace(\"-\", \"/\")}.txt'\n",
        "    with open(label) as f:\n",
        "        for line in f.readlines():\n",
        "            try:\n",
        "                x1, y1, x2, y2, pid = map(int, line.split(',')[:5])\n",
        "                if pid == 0 or pid == 9: continue\n",
        "                true = (x1 * scale, y1 * scale, x2 * scale, y2 * scale)\n",
        "                k = (video, pid)\n",
        "                if k not in polyps:\n",
        "                    polyps[k] = []\n",
        "                for bbox, score in bboxes.get(image[:-4], []):\n",
        "                    iou = calculate_iou(bbox, true)\n",
        "                    if iou > 0:\n",
        "                        polyps[k].append((iou, score))\n",
        "            except Exception as e:\n",
        "                print(label, e, line)\n",
        "\n",
        "for k, v in polyps.items():\n",
        "    v.sort()\n",
        "    vv = []\n",
        "    for x, y in v:\n",
        "        while vv and vv[-1][1] <= y:\n",
        "            vv.pop()\n",
        "        vv.append((x, y))\n",
        "    polyps[k] = vv\n",
        "\n",
        "print(f'Polyps: {len(polyps)}, Max positive: {sum(len(v) > 0 for v in polyps.values())}')\n",
        "print(sum(any(iou > 0.5 and score > 0.3 for iou, score in v) for v in polyps.values()) / len(polyps))\n",
        "\n",
        "xs, ys = np.meshgrid(\n",
        "    np.linspace(1, 0, 101, False),\n",
        "    np.linspace(1, 0, 101, False),\n",
        ")\n",
        "zs = np.ndarray(xs.shape)\n",
        "for i in range(zs.shape[0]):\n",
        "    for j in range(zs.shape[1]):\n",
        "        iou_thres = xs[i][j]\n",
        "        conf_thres = ys[i][j]\n",
        "        cnt = 0\n",
        "        for v in polyps.values():\n",
        "            cnt += any(iou > iou_thres and score > conf_thres for iou, score in v)\n",
        "        zs[i][j] = cnt / len(polyps)\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "# ax.set_title('Test Data')\n",
        "ax.set_xlabel('IoU threshold')\n",
        "ax.set_ylabel('Confidence threshold')\n",
        "ax.set_zlabel('Polyp sensitivity')\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(1, 0)\n",
        "ax.set_zlim(0, 1)\n",
        "ax.plot_surface(xs, ys, zs - 0.005, cmap='plasma', rstride=1, cstride=1, antialiased=False, linewidth=0)\n",
        "ax.plot_wireframe(xs, ys, zs, cstride=5, rstride=5, color='black')\n",
        "fig.show()\n",
        "fig.savefig('polyp_sensitivity.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqOeb_vhDLlY"
      },
      "source": [
        "### Export YOLOv8 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuNmdEd8DLlY",
        "outputId": "4382b134-ee8f-426f-e4d7-24e8024aa38f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.107 ðŸš€ Python-3.10.10 torch-2.0.0 CPU\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8/runs/train/yolov8n12/weights/last.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (34.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.24...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 9.0s, saved as yolov8/runs/train/yolov8n12/weights/last.onnx (11.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i yolov8/runs/train/yolov8n12/weights/last.onnx -o yolov8/runs/train/yolov8n12/weights/last_saved_model -nuo --non_verbose -oiqt -qt per-tensor'\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 253.0s, saved as yolov8/runs/train/yolov8n12/weights/last_saved_model (39.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as yolov8/runs/train/yolov8n12/weights/last_saved_model/last_int8.tflite (3.0 MB)\n",
            "\n",
            "Export complete (255.7s)\n",
            "Results saved to \u001b[1m/mnt/Disk3/snu_project/jeehak/yolov8/runs/train/yolov8n12/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov8/runs/train/yolov8n12/weights/last_saved_model/last_int8.tflite imgsz=640 \n",
            "Validate:        yolo val task=detect model=yolov8/runs/train/yolov8n12/weights/last_saved_model/last_int8.tflite imgsz=640 data=dataset-640x640/data-99-1.yaml \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'yolov8/runs/train/yolov8n12/weights/last_saved_model/last_int8.tflite'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8/runs/train/yolov8n12/weights/last.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "model.export(\n",
        "    format='tflite',\n",
        "    imgsz=640,\n",
        "    optimize=True,\n",
        "    int8=True,\n",
        "    simplify=True,\n",
        "    nms=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f31bc6ce56e5fbb10cee59c3e89f15d91f0c288a7d9827c7026415554f214976"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}